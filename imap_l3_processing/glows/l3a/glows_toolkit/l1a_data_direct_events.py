"""@package docstring
Author: Marek Strumik, maro at cbk.waw.pl
"""
import json
import os
import struct
import copy
import numpy as np
from .constants import VERSION, SUBSECOND_LIMIT
from .time import Time
from .funcs import time_sec_subsec_to_utc
from .direct_event import DirectEvent

class L1aDataDirectEvents():
    """
    L1aDataHistogram() class for GLOWS-L1a-histogram data
    """

    def __init__(self):
        """
        Constructor for this class
        """
        self.data = {}
        self.direct_events = []

    def create_l1a_from_l0_data(self, l0_data, pkts_file_name: str, packet_number: int):
        """
        Sets values of L1a fields using L0 data read from file with CCSDS packets
        Args:
            l0_data: L0 data provided in the form of L0DataDirectEvents object
            pkts_file_name: name of of the file with CCSDS packets
            packet_number: CCSDS packet sequence count (per APID)
        """

        # this is supposed to carry information about errors to be passed up at return
        error_messages = []

        self.data['header'] = {
            'ground_software_version': VERSION,
            'pkts_file_name': pkts_file_name,
            # note: packet number is seq_count (per apid!) field in CCSDS header
            'seq_count_in_pkts_file': packet_number
        }

        self.data['imap_start_time_seconds'] = l0_data['imap_start_time_second']
        self.data['number_of_de_packets'] = l0_data['number_of_de_packets']
        self.data['seq_num_of_de_packet'] = l0_data['seq_num_of_de_packet']
        data = l0_data['de_data'] # data buffer which may contain (data_every_second + DE) data or only DE data

        # we assume that multi-part DE packets have been merged together before execution of this method
        # in the merged packet self.data['seq_num_of_de_packet'] should be set to 0
        assert self.data['seq_num_of_de_packet'] == 0

        # sanity check, we should have:
        # >= 51B = 40 (data_every_second) + 8 (first direct event uncompressed) + 3 (the smallest timedelta + pulse_length)
        # or
        # 40 B if there is only data_every_second structure and no direct events
        #assert len(data) >= 51 or len(data) == 40 # commented out -> see conditions checked later

        # read data_every_second structure
        # based on Jupyter notebook sent in an email by K. Ber on Sep 20, 2023
        # corrected (missing fields filter_temperature and hv_voltage) by looking at
        # glows_appsw-master/tooling/science/models/direct_event_file_model.py:42
        self.data['data_every_second'] = {}
        self.data['data_every_second']['imap_sclk_last_pps'] = int.from_bytes(data[0:4], "big")
        self.data['data_every_second']['glows_sclk_last_pps'] = int.from_bytes(data[4:8], "big")
        self.data['data_every_second']['glows_ssclk_last_pps'] = int.from_bytes(data[8:12], "big")
        self.data['data_every_second']['imap_sclk_next_pps'] = int.from_bytes(data[12:16], "big")
        self.data['data_every_second']['catbed_heater_active'] = False if int(data[16]) == 0 else True
        self.data['data_every_second']['spin_period_valid'] = False if int(data[17]) == 0 else True
        self.data['data_every_second']['spin_phase_at_next_pps_valid'] = False if int(data[18]) == 0 else True
        self.data['data_every_second']['spin_period_source'] = False if int(data[19]) == 0 else True
        self.data['data_every_second']['spin_period'] = int.from_bytes(data[20:22], "big")
        self.data['data_every_second']['spin_phase_at_next_pps'] = int.from_bytes(data[22:24], "big")
        self.data['data_every_second']['number_of_completed_spins'] = int.from_bytes(data[24:28], "big")
        self.data['data_every_second']['filter_temperature'] = int.from_bytes(data[28:30], "big")
        self.data['data_every_second']['hv_voltage'] = int.from_bytes(data[30:32], "big")
        self.data['data_every_second']['glows_time_on_pps_valid'] = False if int(data[32]) == 0 else True
        self.data['data_every_second']['time_status_valid'] = False if int(data[33]) == 0 else True
        self.data['data_every_second']['housekeeping_valid'] = False if int(data[34]) == 0 else True
        self.data['data_every_second']['is_pps_autogenerated'] = False if int(data[35]) == 0 else True
        self.data['data_every_second']['hv_test_in_progress'] = False if int(data[36]) == 0 else True
        self.data['data_every_second']['pulse_test_in_progress'] = False if int(data[37]) == 0 else True
        self.data['data_every_second']['memory_error_detected'] = False if int(data[38]) == 0 else True
        # NOTE: there is one-byte padding in the C structure of data_every_seconds, so it has 40 bytes in total

        # DEBUG TEST
        #print(self.data)
        #exit()
        #print('\nMET', self.data['imap_start_time_seconds'])
        #print('XXX', self.data['data_every_second']['imap_sclk_last_pps'])
        #exit()

        # sanity check
        #assert self.data['imap_start_time_seconds'] == self.data['data_every_second']['imap_sclk_last_pps'], \
        #  'error create_l1a_from_l0_data(): imap_start_time_seconds=%d != imap_sclk_last_pps=%d' % \
        #  (self.data['imap_start_time_seconds'], self.data['data_every_second']['imap_sclk_last_pps'])

        # check if there are any direct events included in the current packet or it contains only data_every_second
        if len(data) == 40:
          return error_messages

        # sanity check, the first direct event must be uncompressed 8-byte structure
        assert len(data) >= 48, \
          'error create_l1a_from_l0_data(): len(data)=%d < 48' % len(data)

        # read the first direct event, which is always uncompressed (i.e., not timedelta but full timestamp)
        current_event = DirectEvent.build_event_from_uncompressed_data(data[40:48])
        self.direct_events.append(current_event)

        # sanity check, the first-direct-event sclk must be within +1 second from data_every_second sclk
        #assert self.direct_events[0].seconds <= self.data['data_every_second']['glows_sclk_last_pps']+1, \
        #    'error create_l1a_from_l0_data(): sclk %d %d' % (self.direct_events[0].seconds, self.data['data_every_second']['glows_sclk_last_pps'])

        # TMP SOLUTION: this if was included instead of the assert above, because in the tests performed in the PTB, some
        # packets had incorrect sclk in the first direct event included; when the bug is fixed by the GLOWS SW team this if
        # should be replaced by the assert above
        if self.direct_events[0].seconds > self.data['data_every_second']['glows_sclk_last_pps']+1:
            print('\n### data_every_second ###')
            print(self.data['data_every_second'])
            print('---')
            print(self.direct_events)
            print('###')
            error_messages.append('DE: de[0].sec %d > glows_sclk_last_pps+1 %d' % (self.direct_events[0].seconds, self.data['data_every_second']['glows_sclk_last_pps']+1))

        # sanity check, KPLabs says that multi event field is actually not processed by AppSW, so it is expected to be False
        # TMP_SOLUTION this assert was commented out but this needs to be discussed with GLOWS FSW team
        #assert self.direct_events[0].multi_event != True, \
        #    'error create_l1a_from_l0_data(): multi event occured'

        # check if there are any compressed direct events included in the current packet
        if len(data) <= 48:
          return error_messages

        # pack the rest of the binary stream into a separate variable to be processed later
        binary_stream_of_timedeltas = data[48:]

        # a test snippet
        #current_event = DirectEvent(54232337, 1997808, 6, False)
        #binary_stream_of_timedeltas = bytearray.fromhex("033b8511061e7bf0") + bytearray.fromhex("876106") + bytearray.fromhex("E7620687") + bytearray.fromhex("00")

        # convert direct events in the form of compressed timedeltas (in a binary stream) into DirectEvent objects
        # based on glows_appsw-master/tooling/science/models/direct_event_file_decompressor.py by KPLabs
        i = 0
        while i < len(binary_stream_of_timedeltas)-1:
            first_byte = int(binary_stream_of_timedeltas[i])
            i += 1
            oldest_diff = first_byte & 0x3F
            marker = first_byte >> 6

            if marker == 0x00 and i <= len(binary_stream_of_timedeltas)-7: # uncompressed time stamp (8-bytes)
                rest_bytes = binary_stream_of_timedeltas[i:i+7]
                i += 7
                part = bytearray([oldest_diff])
                part.extend(rest_bytes)
                current_event = DirectEvent.build_event_from_uncompressed_data(part)

            elif marker == 0x2 and i < len(binary_stream_of_timedeltas)-1: # 2-byte compression of timedelta
                rest = int(binary_stream_of_timedeltas[i])
                i += 1
                diff = oldest_diff << 8 | rest
                length = int(binary_stream_of_timedeltas[i])
                i += 1
                current_event = DirectEvent.build_event_from_compressed_data(diff, length, current_event)

            elif marker == 0x3 and i < len(binary_stream_of_timedeltas)-2: # 3-byte compression of timedelta
                rest = int.from_bytes(binary_stream_of_timedeltas[i:i+2], "big")
                i += 2
                diff = oldest_diff << 16 | rest
                length = int(binary_stream_of_timedeltas[i])
                i += 1
                current_event = DirectEvent.build_event_from_compressed_data(diff, length, current_event)

            else: # wrong-marker or hitting-the-buffer-end case
#                print()
#                pass
#                raise Exception('error create_l1a_from_l0_data(): unexpected marker %d or end of data stream %d %d' % \
#                                (marker, i, len(binary_stream_of_timedeltas)))
                error_messages.append('DE: direct event decompressing failed at byte %d' % (i-1))
                break

            # sanity check
            if current_event.subseconds >= SUBSECOND_LIMIT:
                error_messages.append('DE: de[0].subsec >= SUBSECOND_LIMIT')
                break

            self.direct_events.append(current_event)
        return error_messages

    def generate_file_name(self, extension):
        # file names should be tagged with utc time as suggested in Sec. 1.4.2 of
        # "IMAP SDC to Instrument Team ICD"
        start_time_utc = time_sec_subsec_to_utc(self.data['imap_start_time_seconds'], 0
                                               ).strftime('%Y%m%d%H%M%S')

        # the output file name is constructed using a convention defined in Sec. 1.4.2 of
        # "IMAP SDC to Instrument Team ICD"
        file_name = 'data_l1a_direct_events/imap_glows_l1a_%s_orbX_modX_p_v00.%s' % \
                    (start_time_utc, extension)

        return file_name

    def read_from_file(self, file_name):
        """
        Read L1a data from file
        Args:
            file_name: name of file with L1a data
        """
        # TMP_SOLUTION currently JSON and text format are used, it needs to be changed to CDF when python-cdf
        # modules for IMAP will be provided by SDC
        self.read_from_json_file(file_name)
        self.read_direct_events(file_name.replace('.json', '.dat'))

    def read_from_json_file(self, file_name):
        """
        Read L1a data from file
        Args:
            file_name: name of file with L1a data
        """
        file_handler = open(file_name, 'r')
        self.data = json.load(file_handler)

        # additional field to keep track where data come from
        self.data['l1a_file_name'] = file_name
        file_handler.close()

    def read_direct_events(self, file_name):
        """
        Read L1a data from a three-column text file
        Args:
            file_name: name of text file with L1a data
        """
        self.direct_events = np.loadtxt(file_name, dtype=int)

        # sanity check
        #assert np.shape(self.direct_events)[1] == 3

    def save_data_to_file(self):
        """
        Save generated L1a data to a file
        """
        # TMP_SOLUTION Currently JSON and text formats are used, it needs to be changed to CDF when python-cdf
        # modules for IMAP will be provided by SDC
        self.save_data_to_json_file()
        self.save_direct_events()

    def save_data_to_json_file(self):
        """
        Save generated L1a data to JSON file
        Output file name is set automatically here (TBC if it should be method argument)
        """
        # generate JSON content as string from self.data dictionary
        data = copy.deepcopy(self.data)
        del data['seq_num_of_de_packet']
        json_content = json.dumps(data, indent=4, default=vars)

        file_name = self.generate_file_name('json')

        # sanity check
        # TMP_SOLUTION due to problems with FSW this needed to be commented out, but
        # it seems to be ok to check this when the problems will be fixed
        #if os.path.exists(file_name) and self.data['number_of_de_packets'] == 1:
        #    print('L1a direct-event file already exists, while it should not', file_name)
        #    print(self.data['number_of_de_packets'], self.data['seq_num_of_de_packet'])
        #    exit()

        file_handler = open(file_name, 'w')
        print(json_content, file=file_handler)
        file_handler.close()

    def save_direct_events(self):
        """
        Save direct events data for L1a in a text file with three columns: seconds, subseconds, pulse_length
        Output file name is set automatically here (TBC if it should be method argument)
        """

        file_name = self.generate_file_name('dat')
        file_handler = open(file_name, 'w')
        for i, x in enumerate(self.direct_events):
            file_handler.write('%d %7d %3d\n' % (x.seconds, x.subseconds, x.impulse_length))
        file_handler.close()
